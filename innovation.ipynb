{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cea918",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "FINAL TASK-2(b) HYBRID QUERY FEDERATION SYSTEM - FULL FEATURE MAX\n",
    "- Fully merged: hybrid similarity reranker, embedding-based expansion,\n",
    "  safer numeric extraction, top-K BNS candidates, offence->section mapping,\n",
    "  structured JSON LLM synthesis (jurisdiction-locked), and fallback JSON generation.\n",
    "- Requirements:\n",
    "    pip install sentence-transformers rapidfuzz numpy requests google-generativeai\n",
    "  (google-generativeai optional if you want real Gemini; fallback will work without it)\n",
    "- Usage:\n",
    "    python full_pipeline.py\n",
    "\"\"\"\n",
    "\n",
    "import sqlite3\n",
    "import json\n",
    "import requests\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "from pprint import pprint\n",
    "import traceback\n",
    "\n",
    "# optional Gemini wrapper\n",
    "try:\n",
    "    import google.generativeai as genai\n",
    "except Exception:\n",
    "    genai = None\n",
    "\n",
    "# hybrid similarity imports\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from rapidfuzz import distance, fuzz\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# CONFIGURATION\n",
    "# ------------------------------------------------------------\n",
    "CRPC_SERVER = \"http://192.168.226.115:5000\"\n",
    "BNS_DB_PATH = \"bns.db\"\n",
    "CASES_JSON = \"legal_cases.json\"\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\", \"\")  # optional: set in environment\n",
    "\n",
    "# Hybrid similarity weights (alpha: Jaccard, beta: Edit, gamma: Embedding)\n",
    "ALPHA, BETA, GAMMA = 0.3, 0.3, 0.4\n",
    "EMBEDDING_MODEL = \"all-MiniLM-L6-v2\"\n",
    "HYBRID_TOP_K = 5  # number of top candidates to show\n",
    "\n",
    "# Candidate expansion settings\n",
    "EMBED_EXPAND_THRESHOLD = 5   # if <= this many bns_hits, expand with embedding search\n",
    "EMBED_EXPAND_LIMIT = 80      # how many top similar to fetch when expanding\n",
    "\n",
    "# misc\n",
    "MAX_CAND = 300\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# DB / Cases load\n",
    "# ------------------------------------------------------------\n",
    "if not os.path.exists(BNS_DB_PATH):\n",
    "    print(\"WARNING: BNS DB not found at\", BNS_DB_PATH)\n",
    "BNS = sqlite3.connect(BNS_DB_PATH)\n",
    "BNS.row_factory = sqlite3.Row\n",
    "\n",
    "try:\n",
    "    LEGAL_CASES = json.load(open(CASES_JSON, \"r\"))\n",
    "except Exception:\n",
    "    LEGAL_CASES = []\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Embedding model cache\n",
    "# ------------------------------------------------------------\n",
    "_embedding_model = None\n",
    "\n",
    "def get_embedding_model():\n",
    "    global _embedding_model\n",
    "    if _embedding_model is None:\n",
    "        _embedding_model = SentenceTransformer(EMBEDDING_MODEL)\n",
    "    return _embedding_model\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# IPC → BNS OFFICIAL MAPPING (kept)\n",
    "# ------------------------------------------------------------\n",
    "IPC_TO_BNS = {\n",
    "    \"420\": [316,317,318,319],\n",
    "    \"417\": [316],\n",
    "    \"415\": [315],\n",
    "    \"376\": [63,64,65],\n",
    "    \"302\": [103],\n",
    "    \"304\": [104],\n",
    "    \"307\": [109],\n",
    "    \"354\": [73]\n",
    "}\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Helper: Gemini wrapper (optional) + robust fallback (including JSON)\n",
    "# ------------------------------------------------------------\n",
    "def call_gemini(prompt, max_tokens=512, timeout=10.0):\n",
    "    \"\"\"\n",
    "    Use real Gemini API if configured. Otherwise use a deterministic fallback.\n",
    "    Fallback also attempts to return structured JSON mappings when prompt requests JSON.\n",
    "    \"\"\"\n",
    "    prompt_l = (prompt or \"\").lower()\n",
    "\n",
    "    # real Gemini if available\n",
    "    if GEMINI_API_KEY and genai is not None:\n",
    "        try:\n",
    "            genai.configure(api_key=GEMINI_API_KEY)\n",
    "            model = genai.GenerativeModel(\"models/gemini-2.5-pro\")\n",
    "            # Basic generate_content call; production code should set safety params\n",
    "            response = model.generate_content(prompt, max_output_tokens=max_tokens, timeout=timeout)\n",
    "            if hasattr(response, \"text\"):\n",
    "                return response.text\n",
    "            return str(response)\n",
    "        except Exception as e:\n",
    "            # fall through to fallback, but include error note\n",
    "            return f\"[Gemini Error] {str(e)}\\n\\n\" + _fallback_gemini(prompt)\n",
    "\n",
    "    # fallback\n",
    "    return _fallback_gemini(prompt)\n",
    "\n",
    "def _fallback_gemini(prompt):\n",
    "    \"\"\"\n",
    "    Deterministic fallback generator:\n",
    "    - If prompt asks for JSON mapping (contains 'return a json' or 'mappings'), emit JSON mapping heuristically.\n",
    "    - Else if prompt asks to extract crimes, attempt structured JSON of crimes.\n",
    "    - Else short summary fallback.\n",
    "    \"\"\"\n",
    "    prompt_l = (prompt or \"\").lower()\n",
    "\n",
    "    # JSON mapping request (structured LLM)\n",
    "    if \"return a json object\" in prompt_l or '\"mappings\"' in prompt_l or \"output only valid json\" in prompt_l:\n",
    "        # naive mapping table - expand as per needs\n",
    "        naive = {\n",
    "            \"murder\": {\"bns\":[103], \"ipc\":[302], \"reason\":\"Intentional killing → murder provisions\"},\n",
    "            \"kidnap\": {\"bns\":[142], \"ipc\":[364], \"reason\":\"Abduction/kidnapping provisions\"},\n",
    "            \"kidnapping\": {\"bns\":[142], \"ipc\":[364], \"reason\":\"Abduction/kidnapping provisions\"},\n",
    "            \"rape\": {\"bns\":[65], \"ipc\":[],\"reason\":\"Sexual assault; POCSO if victim minor\"},\n",
    "            \"extortion\": {\"bns\":[232], \"ipc\":[384], \"reason\":\"Threats/demands of money\"},\n",
    "            \"threat\": {\"bns\":[232], \"ipc\":[503], \"reason\":\"Criminal intimidation / threats\"},\n",
    "            \"dismember\": {\"bns\":[201], \"ipc\":[201], \"reason\":\"Destruction of evidence / dismemberment\"},\n",
    "            \"robbery\": {\"bns\":[313], \"ipc\":[392], \"reason\":\"Robbery provisions\"},\n",
    "            \"cheat\": {\"bns\":[173], \"ipc\":[420], \"reason\":\"Cheating / fraud\"}\n",
    "        }\n",
    "        mappings = []\n",
    "        for k,v in naive.items():\n",
    "            if k in prompt_l:\n",
    "                mappings.append({\n",
    "                    \"offence\": k,\n",
    "                    \"suggested_bns\": v[\"bns\"],\n",
    "                    \"suggested_ipc\": v.get(\"ipc\", []),\n",
    "                    \"reason\": v.get(\"reason\",\"\")\n",
    "                })\n",
    "        # If none matched heuristically, include a generic mapping hint\n",
    "        if not mappings:\n",
    "            mappings.append({\n",
    "                \"offence\": \"unknown\",\n",
    "                \"suggested_bns\": [],\n",
    "                \"suggested_ipc\": [],\n",
    "                \"reason\": \"No direct keyword matched; please rely on retrieval candidates.\"\n",
    "            })\n",
    "        return json.dumps({\"mappings\": mappings}, indent=2)\n",
    "\n",
    "    # extraction prompt asked for crimes JSON\n",
    "    if \"extract all crimes\" in prompt_l or \"identify all crimes\" in prompt_l or '\"crimes\"' in prompt_l:\n",
    "        detected = []\n",
    "        for k, v in [\n",
    "            (\"kidnap\", \"Kidnapping\"),\n",
    "            (\"abduct\", \"Kidnapping\"),\n",
    "            (\"rape\", \"Rape\"),\n",
    "            (\"sexual assault\", \"Rape\"),\n",
    "            (\"murder\", \"Murder\"),\n",
    "            (\"kill\", \"Murder\"),\n",
    "            (\"strangle\", \"Murder\"),\n",
    "            (\"threat\", \"Criminal Intimidation\"),\n",
    "            (\"extort\", \"Extortion\"),\n",
    "            (\"money\", \"Extortion\"),\n",
    "            (\"cut\", \"Destruction of Evidence\"),\n",
    "            (\"dismember\", \"Destruction of Evidence\"),\n",
    "            (\"rob\", \"Robbery\"),\n",
    "            (\"steal\", \"Theft\")\n",
    "        ]:\n",
    "            if k in prompt_l and v not in detected:\n",
    "                detected.append(v)\n",
    "        return json.dumps({\"crimes\":[{\"crime\":c,\"confidence\":0.8} for c in detected]}, indent=2)\n",
    "\n",
    "    # long narrative fallback\n",
    "    if len(prompt_l) > 300:\n",
    "        return \"LLM summary (fallback): Narrative contains multiple offences; refer to relevant sections.\"\n",
    "\n",
    "    # default short fallback\n",
    "    return \"LLM answer (fallback): Refer to the fetched sections from BNS/CRPC and case-law for details.\"\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1. QUERY REWRITE (with safer numeric extraction)\n",
    "# ------------------------------------------------------------\n",
    "def rewrite_query(q):\n",
    "    q0 = q or \"\"\n",
    "    ql = q0.lower()\n",
    "    bns_kw, crpc_kw = [], []\n",
    "\n",
    "    # crime detection rules\n",
    "    if any(w in ql for w in [\"rape\",\"sexual\"]):\n",
    "        bns_kw += [\"rape\",\"sexual\",\"woman\"]\n",
    "        crpc_kw += [\"rape\"]\n",
    "    if any(w in ql for w in [\"cheat\",\"fraud\",\"dishonest\",\"deceiv\"]):\n",
    "        bns_kw += [\"cheat\",\"fraud\",\"dishonest\"]\n",
    "        crpc_kw += [\"cheating\",\"420\"]\n",
    "    if any(w in ql for w in [\"murder\",\"kill\",\"homicide\",\"strangle\",\"stab\"]):\n",
    "        bns_kw += [\"murder\",\"kill\",\"death\",\"homicide\"]\n",
    "        crpc_kw += [\"murder\",\"302\"]\n",
    "    if any(w in ql for w in [\"kidnap\",\"abduct\",\"abduction\"]):\n",
    "        bns_kw += [\"kidnap\",\"abduct\"]\n",
    "        crpc_kw += [\"kidnapping\"]\n",
    "    if any(w in ql for w in [\"threat\",\"intimidat\",\"blackmail\",\"extort\",\"demand money\"]):\n",
    "        bns_kw += [\"threat\",\"intimidation\",\"extortion\"]\n",
    "        crpc_kw += [\"intimidation\",\"extortion\"]\n",
    "    if any(w in ql for w in [\"rob\",\"robbery\",\"steal\",\"theft\"]):\n",
    "        bns_kw += [\"robbery\",\"theft\"]\n",
    "        crpc_kw += [\"robbery\",\"theft\"]\n",
    "\n",
    "    # explicit sections only (safer)\n",
    "    explicit_sections = re.findall(r\"\\b(?:section|sec|s\\.)\\s+(\\d{2,4})\\b\", ql)\n",
    "    explicit_sections = [s for s in explicit_sections if len(s) >= 2]\n",
    "\n",
    "    # optional numeric detection (filtered) - we prefer explicit only\n",
    "    raw_nums = re.findall(r\"\\b(\\d{1,4})\\b\", ql)\n",
    "    candidates = []\n",
    "    for n in raw_nums:\n",
    "        if n in explicit_sections:\n",
    "            candidates.append(n); continue\n",
    "        if re.search(rf\"\\b{n}\\s*(?:years?|yrs?|year|old|y/o|age)\\b\", ql) or re.search(rf\"\\b(?:years?|yrs?|year|old|y/o|age)\\s*{n}\\b\", ql):\n",
    "            continue\n",
    "        if re.search(rf\"(?:₹|rs\\.?|rupees|lakhs|lakh)\\s*{n}\\b\", ql) or re.search(rf\"\\b{n}\\s*(?:lakhs|lakh|rupees|rs\\.?)\\b\", ql):\n",
    "            continue\n",
    "        if int(n) < 18 and re.search(rf\"\\b(?:girl|boy|child|minor|infant|kid)\\b\", ql):\n",
    "            continue\n",
    "        candidates.append(n)\n",
    "\n",
    "    # default to explicit sections only\n",
    "    sections = list(dict.fromkeys(explicit_sections))\n",
    "\n",
    "    intent = {\n",
    "        \"is_crime_story\": any(k in ql for k in [\"kidnap\",\"murder\",\"rape\",\"threat\",\"extort\",\"rob\",\"stalk\",\"abduct\"]),\n",
    "        \"is_section_lookup\": bool(re.search(r\"\\b(?:section|sec|s\\.)\\s+\\d{2,4}\\b\", ql)),\n",
    "        \"is_definition\": any(w in ql for w in [\"what is\",\"explain\",\"define\",\"meaning of\"]),\n",
    "        \"is_comparison\": any(w in ql for w in [\"compare\",\"difference\",\"vs\",\"versus\"])\n",
    "    }\n",
    "\n",
    "    return {\n",
    "        \"bns_keywords\": list(dict.fromkeys(bns_kw)),\n",
    "        \"crpc_keywords\": list(dict.fromkeys(crpc_kw)),\n",
    "        \"sections\": sections,\n",
    "        \"raw_query\": q0,\n",
    "        \"intent\": intent\n",
    "    }\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2. BNS SEARCH (SECTION & KEYWORD)\n",
    "# ------------------------------------------------------------\n",
    "def bns_by_section(s):\n",
    "    cur = BNS.cursor()\n",
    "    try:\n",
    "        s_int = int(s)\n",
    "    except Exception:\n",
    "        return []\n",
    "    cur.execute(\"\"\"\n",
    "        SELECT section AS section_id, section__name AS title, description AS text\n",
    "        FROM bns_sections\n",
    "        WHERE section = ?\n",
    "    \"\"\", (s_int,))\n",
    "    return [dict(r) for r in cur.fetchall()]\n",
    "\n",
    "def bns_by_keyword(kw):\n",
    "    cur = BNS.cursor()\n",
    "    k = f\"%{kw.lower()}%\"\n",
    "    cur.execute(\"\"\"\n",
    "        SELECT section AS section_id, section__name AS title, description AS text\n",
    "        FROM bns_sections\n",
    "        WHERE LOWER(section__name) LIKE ?\n",
    "           OR LOWER(description) LIKE ?\n",
    "    \"\"\", (k, k))\n",
    "    return [dict(r) for r in cur.fetchall()]\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3. CRPC SEARCH (REMOTE)\n",
    "# ------------------------------------------------------------\n",
    "def crpc_search(kw):\n",
    "    if not kw:\n",
    "        return []\n",
    "    try:\n",
    "        r = requests.get(f\"{CRPC_SERVER}/search_crpc\",\n",
    "                         params={\"q\": kw, \"limit\": 10},\n",
    "                         timeout=1.5)\n",
    "        if r.ok:\n",
    "            return r.json()\n",
    "    except Exception:\n",
    "        try:\n",
    "            r = requests.get(f\"{CRPC_SERVER}/search_crpc\",\n",
    "                             params={\"q\": kw, \"limit\": 10},\n",
    "                             timeout=3.0)\n",
    "            if r.ok:\n",
    "                return r.json()\n",
    "        except Exception:\n",
    "            pass\n",
    "    return []\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4. CASE SEARCH\n",
    "# ------------------------------------------------------------\n",
    "def case_search(keywords):\n",
    "    out = []\n",
    "    if not LEGAL_CASES:\n",
    "        return []\n",
    "    for c in LEGAL_CASES:\n",
    "        t = json.dumps(c).lower()\n",
    "        if any(k.lower() in t for k in keywords[:6]):\n",
    "            out.append(c)\n",
    "    return out if out else LEGAL_CASES[:2]\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# EMBEDDING-BASED CANDIDATE EXPANSION\n",
    "# ------------------------------------------------------------\n",
    "def expand_candidates_with_embeddings(query, current_candidates, all_limit=EMBED_EXPAND_LIMIT):\n",
    "    \"\"\"\n",
    "    If current_candidates is small, fetch top-N similar sections from entire BNS using embeddings.\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(BNS_DB_PATH)\n",
    "    conn.row_factory = sqlite3.Row\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"SELECT section AS section_id, section__name AS title, description AS text FROM bns_sections\")\n",
    "    rows = [dict(r) for r in cur.fetchall()]\n",
    "    conn.close()\n",
    "\n",
    "    combined_texts = [ (str(r.get(\"title\",\"\")) + \" \" + str(r.get(\"text\",\"\"))).strip() for r in rows ]\n",
    "    model = get_embedding_model()\n",
    "    all_emb = model.encode([query] + combined_texts, convert_to_numpy=True, show_progress_bar=False)\n",
    "    q_emb = all_emb[0]\n",
    "    rows_embs = all_emb[1:]\n",
    "\n",
    "    sims = []\n",
    "    for i, r in enumerate(rows):\n",
    "        emb = rows_embs[i]\n",
    "        denom = (np.linalg.norm(q_emb) * np.linalg.norm(emb))\n",
    "        sim = 0.0\n",
    "        if denom != 0:\n",
    "            sim = float(np.dot(q_emb, emb) / denom)\n",
    "        sims.append((i, sim))\n",
    "    sims_sorted = sorted(sims, key=lambda x: x[1], reverse=True)[:all_limit]\n",
    "    extended = [ rows[i] for i, _ in sims_sorted ]\n",
    "\n",
    "    # include current_candidates at front, dedupe\n",
    "    seen = set()\n",
    "    out = []\n",
    "    for s in (current_candidates + extended):\n",
    "        sid = s.get(\"section_id\")\n",
    "        if sid not in seen:\n",
    "            out.append(s); seen.add(sid)\n",
    "    return out\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# HYBRID SIMILARITY UTILITIES\n",
    "# ------------------------------------------------------------\n",
    "def tokenize_set(s: str):\n",
    "    if not s:\n",
    "        return set()\n",
    "    s = re.sub(r\"[^a-z0-9\\s]\", \" \", s.lower())\n",
    "    toks = [t for t in s.split() if len(t) > 1]\n",
    "    return set(toks)\n",
    "\n",
    "def jaccard_similarity(a: str, b: str) -> float:\n",
    "    ta = tokenize_set(a); tb = tokenize_set(b)\n",
    "    if not ta and not tb: return 1.0\n",
    "    if not ta or not tb: return 0.0\n",
    "    inter = ta.intersection(tb); union = ta.union(tb)\n",
    "    return len(inter) / len(union)\n",
    "\n",
    "def edit_similarity(a: str, b: str) -> float:\n",
    "    if (not a) and (not b): return 1.0\n",
    "    if (not a) or (not b): return 0.0\n",
    "    try:\n",
    "        sim = distance.Levenshtein.normalized_similarity(a, b)\n",
    "        return float(sim)\n",
    "    except Exception:\n",
    "        return float(fuzz.token_sort_ratio(a, b) / 100.0)\n",
    "\n",
    "def embedding_cosine_sim(a_emb: np.ndarray, b_emb: np.ndarray) -> float:\n",
    "    if a_emb is None or b_emb is None: return 0.0\n",
    "    num = float(np.dot(a_emb, b_emb))\n",
    "    denom = float(np.linalg.norm(a_emb) * np.linalg.norm(b_emb))\n",
    "    if denom == 0: return 0.0\n",
    "    sim = num / denom\n",
    "    return (sim + 1.0) / 2.0\n",
    "\n",
    "def hybrid_score(text_a: str, text_b: str,\n",
    "                 alpha=ALPHA, beta=BETA, gamma=GAMMA,\n",
    "                 a_emb=None, b_emb=None) -> dict:\n",
    "    j = jaccard_similarity(text_a, text_b)\n",
    "    e = edit_similarity(text_a, text_b)\n",
    "    if a_emb is None or b_emb is None:\n",
    "        model = get_embedding_model()\n",
    "        emb = model.encode([text_a, text_b], convert_to_numpy=True, show_progress_bar=False)\n",
    "        a_emb, b_emb = emb[0], emb[1]\n",
    "    c = embedding_cosine_sim(a_emb, b_emb)\n",
    "    score = alpha * j + beta * e + gamma * c\n",
    "    return {\"score\": score, \"jaccard\": j, \"edit\": e, \"embed\": c}\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5. BEST BNS SECTION SELECTION (returns top-N ranked list)\n",
    "# ------------------------------------------------------------\n",
    "def choose_best_bns(query, bns_hits, rerank_top_n=HYBRID_TOP_K):\n",
    "    q = (query or \"\").strip()\n",
    "    if not bns_hits:\n",
    "        return []\n",
    "\n",
    "    # Expand if small\n",
    "    if len(bns_hits) <= EMBED_EXPAND_THRESHOLD:\n",
    "        try:\n",
    "            bns_hits = expand_candidates_with_embeddings(q, bns_hits, all_limit=EMBED_EXPAND_LIMIT)\n",
    "        except Exception as e:\n",
    "            print(\"embedding expansion failed:\", e)\n",
    "\n",
    "    # Build candidate combined texts\n",
    "    candidates = []\n",
    "    for s in bns_hits:\n",
    "        combined = ((str(s.get(\"title\",\"\")) or \"\") + \" \" + (str(s.get(\"text\",\"\")) or \"\")).strip()\n",
    "        candidates.append({\"section_id\": s.get(\"section_id\"), \"title\": s.get(\"title\"), \"text\": s.get(\"text\"), \"combined\": combined, \"_raw\": s})\n",
    "\n",
    "    if len(candidates) > MAX_CAND:\n",
    "        candidates = candidates[:MAX_CAND]\n",
    "\n",
    "    model = get_embedding_model()\n",
    "    texts_to_embed = [q] + [c[\"combined\"] for c in candidates]\n",
    "    all_emb = model.encode(texts_to_embed, convert_to_numpy=True, show_progress_bar=False)\n",
    "    q_emb = all_emb[0]\n",
    "    cand_embs = all_emb[1:]\n",
    "\n",
    "    scored = []\n",
    "    for i, c in enumerate(candidates):\n",
    "        s_emb = cand_embs[i]\n",
    "        sc = hybrid_score(q, c[\"combined\"], a_emb=q_emb, b_emb=s_emb)\n",
    "        entry = dict(c[\"_raw\"])  # original row dict\n",
    "        entry[\"_score\"] = float(sc[\"score\"])\n",
    "        entry[\"_jaccard\"] = float(sc[\"jaccard\"])\n",
    "        entry[\"_edit\"] = float(sc[\"edit\"])\n",
    "        entry[\"_embed\"] = float(sc[\"embed\"])\n",
    "        scored.append(entry)\n",
    "\n",
    "    scored_sorted = sorted(scored, key=lambda x: x[\"_score\"], reverse=True)\n",
    "    return scored_sorted[:rerank_top_n]\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6. CRIME EXTRACTION (rules + LLM) - unchanged\n",
    "# ------------------------------------------------------------\n",
    "def rule_based_extract_crimes(text):\n",
    "    t = (text or \"\").lower()\n",
    "    detected = []\n",
    "    if any(w in t for w in [\"kidnap\",\"abduct\",\"abduction\"]):\n",
    "        detected.append(\"Kidnapping\")\n",
    "    if any(w in t for w in [\"rape\",\"sexual assault\",\"sexual\"]):\n",
    "        detected.append(\"Rape\")\n",
    "    if any(w in t for w in [\"murder\",\"kill\",\"homicide\",\"strangle\",\"stab\"]):\n",
    "        detected.append(\"Murder\")\n",
    "    if any(w in t for w in [\"threat\",\"intimidation\",\"blackmail\",\"extort\"]):\n",
    "        detected.append(\"Criminal Intimidation / Extortion\")\n",
    "    if any(w in t for w in [\"dismember\",\"cut body\",\"chop\",\"body parts\"]):\n",
    "        detected.append(\"Destruction of Evidence / Dismemberment\")\n",
    "    if any(w in t for w in [\"rob\",\"steal\",\"theft\"]):\n",
    "        detected.append(\"Robbery / Theft\")\n",
    "    return list(dict.fromkeys(detected))\n",
    "\n",
    "def llm_extract_crimes_full(text):\n",
    "    prompt = (\n",
    "        \"Extract all crimes from the following narrative and return JSON: \"\n",
    "        '{\"crimes\":[{\"crime\":\"...\",\"details\":\"...\"}]} '\n",
    "        \"Narrative:\\n\\n\" + (text or \"\")\n",
    "    )\n",
    "    res = call_gemini(prompt)\n",
    "    try:\n",
    "        if isinstance(res, str):\n",
    "            parsed = json.loads(res)\n",
    "            crimes = [c.get(\"crime\") for c in parsed.get(\"crimes\", []) if c.get(\"crime\")]\n",
    "            return list(dict.fromkeys(crimes))\n",
    "    except Exception:\n",
    "        pass\n",
    "    return rule_based_extract_crimes(text)\n",
    "\n",
    "def hybrid_extract_crimes(text):\n",
    "    rules = rule_based_extract_crimes(text)\n",
    "    llm = llm_extract_crimes_full(text)\n",
    "    merged = list(dict.fromkeys(rules + llm))\n",
    "    provenance = {\"rules\": rules, \"llm\": llm, \"merged\": merged}\n",
    "    return provenance\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 7. Offence -> Section Mapping Helper\n",
    "# ------------------------------------------------------------\n",
    "def map_offences_to_sections(query, offences, bns_candidates):\n",
    "    \"\"\"\n",
    "    For each offence string, produce a ranked list of candidate sections (top-K).\n",
    "    Uses IPC->BNS seeds, keyword lookup, and reranking on the candidate pool.\n",
    "    \"\"\"\n",
    "    mapping = {}\n",
    "    # small IPC heuristic table (extend as needed)\n",
    "    IPC_MAP = {\n",
    "        \"murder\": \"302\",\n",
    "        \"kidnapping\": \"364\",\n",
    "        \"kidnap\": \"364\",\n",
    "        \"rape\": None,\n",
    "        \"extortion\": \"384\",\n",
    "        \"criminal intimidation\": None,\n",
    "        \"criminal intimidation / extortion\": None\n",
    "    }\n",
    "\n",
    "    for off in (offences or []):\n",
    "        off_l = off.lower()\n",
    "        seeds = []\n",
    "\n",
    "        # use IPC_MAP if available\n",
    "        ipc = IPC_MAP.get(off_l)\n",
    "        if ipc and ipc in IPC_TO_BNS:\n",
    "            for b in IPC_TO_BNS[ipc]:\n",
    "                seeds += bns_by_section(b)\n",
    "\n",
    "        # keyword fallback from the offence tokens\n",
    "        tokens = re.findall(r\"\\w+\", off_l)\n",
    "        for tok in tokens:\n",
    "            try:\n",
    "                seeds += bns_by_keyword(tok)\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        # always include the current bns_candidates if provided\n",
    "        seeds += bns_candidates\n",
    "\n",
    "        # dedupe seeds\n",
    "        flat = []\n",
    "        seen = set()\n",
    "        for s in seeds:\n",
    "            if not s: continue\n",
    "            sid = s.get(\"section_id\")\n",
    "            if sid not in seen:\n",
    "                flat.append(s); seen.add(sid)\n",
    "\n",
    "        if not flat:\n",
    "            flat = bns_candidates\n",
    "\n",
    "        # rerank these for this offence\n",
    "        ranked = choose_best_bns(query, flat, rerank_top_n=HYBRID_TOP_K)\n",
    "        mapping[off] = ranked\n",
    "\n",
    "    return mapping\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 8. FINAL SYNTHESIS (top-K BNS output + structured LLM JSON mapping)\n",
    "# ------------------------------------------------------------\n",
    "def final_answer(query, bns_hits, crpc_hits, cases, crime_provenance=None):\n",
    "    # get top-K BNS candidates\n",
    "    top_list = choose_best_bns(query, bns_hits, rerank_top_n=HYBRID_TOP_K)\n",
    "\n",
    "    answer_lines = []\n",
    "    answer_lines.append(\"Final Legal Summary:\")\n",
    "\n",
    "    if top_list:\n",
    "        answer_lines.append(\"\\n• Top BNS candidate sections (ranked):\")\n",
    "        for t in top_list:\n",
    "            answer_lines.append(f\"  - BNS {t.get('section_id')}: {t.get('title')}  (score={t.get('_score'):.3f})\")\n",
    "            snippet = (t.get(\"text\",\"\") or \"\")[:300].replace(\"\\n\", \" \")\n",
    "            if snippet:\n",
    "                answer_lines.append(f\"     Snippet: {snippet}\")\n",
    "    else:\n",
    "        answer_lines.append(\"\\n• No relevant BNS section found.\")\n",
    "\n",
    "    if crpc_hits:\n",
    "        c = crpc_hits[0]\n",
    "        if isinstance(c, dict):\n",
    "            secid = c.get(\"section_id\", c.get(\"section\", \"N/A\"))\n",
    "            title = c.get(\"title\", c.get(\"section__name\", \"CRPC match\"))\n",
    "            answer_lines.append(f\"\\n• Relevant CRPC Section {secid}: {title}\")\n",
    "        else:\n",
    "            answer_lines.append(f\"\\n• Relevant CRPC hit (raw): {str(c)[:120]}\")\n",
    "\n",
    "    if cases:\n",
    "        answer_lines.append(f\"\\n• {len(cases)} related case(s) identified.\")\n",
    "\n",
    "    if crime_provenance:\n",
    "        pr = crime_provenance\n",
    "        answer_lines.append(\"\\nDetected Offences (provenance):\")\n",
    "        answer_lines.append(f\" - rules: {pr.get('rules', [])}\")\n",
    "        answer_lines.append(f\" - llm: {pr.get('llm', [])}\")\n",
    "        answer_lines.append(f\" - merged: {pr.get('merged', [])}\")\n",
    "\n",
    "    answer_lines.append(\"\\n(End of deterministic summary.)\")\n",
    "\n",
    "    # Create an offence -> section mapping using deterministic seeds + rerank\n",
    "    offence_mapping = {}\n",
    "    if crime_provenance and top_list:\n",
    "        try:\n",
    "            offence_mapping = map_offences_to_sections(query, crime_provenance.get(\"merged\", []), bns_hits)\n",
    "        except Exception:\n",
    "            offence_mapping = {}\n",
    "\n",
    "    # Jurisdiction-locked LLM prompt requesting JSON mapping\n",
    "    llm_prompt = (\n",
    "        \"You are a legal assistant that MUST answer ONLY using Indian law (BNS, BNSS, BSA, POCSO). \"\n",
    "        \"Do NOT use U.S., UK, or any foreign legal frameworks. \"\n",
    "        \"Return a JSON object with this schema:\\n\"\n",
    "        '{ \"mappings\": ['\n",
    "        '  {\"offence\":\"<offence name>\", \"suggested_bns\":[<section_numbers>], '\n",
    "        '   \"suggested_ipc\":[<ipc_numbers_optional>], \"reason\":\"<one-line reason>\"}'\n",
    "        '  , ... ] }\\n\\n'\n",
    "        \"Use the query below and the deterministic candidate list when possible. Output ONLY valid JSON.\\n\\n\"\n",
    "        + (query or \"\")\n",
    "    )\n",
    "\n",
    "    llm_block = call_gemini(llm_prompt)\n",
    "    # try to parse JSON from LLM\n",
    "    llm_json = None\n",
    "    try:\n",
    "        m = re.search(r\"(\\{.*\\})\", llm_block, flags=re.S)\n",
    "        if m:\n",
    "            llm_json = json.loads(m.group(1))\n",
    "        else:\n",
    "            llm_json = json.loads(llm_block)\n",
    "    except Exception:\n",
    "        llm_json = None\n",
    "\n",
    "    answer_lines.append(\"\\nLLM Synthesis:\")\n",
    "\n",
    "    if llm_json and isinstance(llm_json, dict):\n",
    "        for entry in llm_json.get(\"mappings\", []):\n",
    "            off = entry.get(\"offence\")\n",
    "            bns_list = entry.get(\"suggested_bns\", [])\n",
    "            ipc_list = entry.get(\"suggested_ipc\", [])\n",
    "            reason = entry.get(\"reason\", \"\")\n",
    "            answer_lines.append(f\" - {off}: BNS {bns_list} IPC {ipc_list} ; {reason}\")\n",
    "    else:\n",
    "        # fallback: show deterministic offence mapping (if any) and raw LLM text\n",
    "        if offence_mapping:\n",
    "            answer_lines.append(\"Deterministic offence -> candidate sections (from re-ranker):\")\n",
    "            for off, secs in offence_mapping.items():\n",
    "                answer_lines.append(f\" - {off}: \" + \", \".join([str(s.get(\"section_id\")) + f\"(score={s.get('_score'):.3f})\" for s in secs]))\n",
    "        answer_lines.append(\"\\nLLM Raw Output (fallback):\")\n",
    "        answer_lines.append(str(llm_block))\n",
    "\n",
    "    return \"\\n\".join(answer_lines)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 9. MAIN PIPELINE - unified ask() entrypoint\n",
    "# ------------------------------------------------------------\n",
    "def run_pipeline(query):\n",
    "    return ask(query)\n",
    "\n",
    "def ask(query):\n",
    "    # Step 1: rewrite + intent detection\n",
    "    print(\"\\n=== TASK-2(b) HYBRID ARCHITECTURE DEMO ===\")\n",
    "    print(\"\\n>> STEP 1: QUERY REWRITE + INTENT\")\n",
    "    rewrite = rewrite_query(query)\n",
    "    pprint(rewrite)\n",
    "\n",
    "    # Step 1.5: hybrid crime extraction for long narratives\n",
    "    crime_prov = None\n",
    "    if rewrite[\"intent\"].get(\"is_crime_story\") or len(query) > 120:\n",
    "        crime_prov = hybrid_extract_crimes(query)\n",
    "        print(\"\\nDetected offences (hybrid):\")\n",
    "        pprint(crime_prov)\n",
    "\n",
    "    # ------------------------------------\n",
    "    # BNS Federation (blocking)\n",
    "    # ------------------------------------\n",
    "    bns_hits = []\n",
    "\n",
    "    # 1. Direct BNS section lookup (explicit numbers or IPC->BNS)\n",
    "    for sec in rewrite[\"sections\"]:\n",
    "        bns_hits += bns_by_section(sec)\n",
    "        if sec in IPC_TO_BNS:\n",
    "            for mapped in IPC_TO_BNS[sec]:\n",
    "                bns_hits += bns_by_section(mapped)\n",
    "\n",
    "    # 2. Keyword search using rewrite keywords and also include rules/llm extracted crime keywords\n",
    "    if not bns_hits:\n",
    "        search_keys = rewrite[\"bns_keywords\"][:10]\n",
    "        if crime_prov:\n",
    "            search_keys += crime_prov.get(\"merged\", [])[:6]\n",
    "        for kw in search_keys:\n",
    "            try:\n",
    "                bns_hits += bns_by_keyword(kw)\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    # deduplicate BNS hits by section_id (preserve order)\n",
    "    seen = set()\n",
    "    uniq_bns = []\n",
    "    for s in bns_hits:\n",
    "        sid = s.get(\"section_id\")\n",
    "        if sid not in seen:\n",
    "            uniq_bns.append(s)\n",
    "            seen.add(sid)\n",
    "    bns_hits = uniq_bns\n",
    "\n",
    "    print(f\"\\nBNS hits: {len(bns_hits)}\")\n",
    "\n",
    "    # If too few candidates, expand using embeddings\n",
    "    if len(bns_hits) <= EMBED_EXPAND_THRESHOLD:\n",
    "        try:\n",
    "            bns_hits = expand_candidates_with_embeddings(query, bns_hits, all_limit=EMBED_EXPAND_LIMIT)\n",
    "            # dedupe after expansion\n",
    "            seen = set(); uniq_bns = []\n",
    "            for s in bns_hits:\n",
    "                sid = s.get(\"section_id\")\n",
    "                if sid not in seen:\n",
    "                    uniq_bns.append(s); seen.add(sid)\n",
    "            bns_hits = uniq_bns\n",
    "            print(f\"BNS hits after embedding expansion: {len(bns_hits)}\")\n",
    "        except Exception as e:\n",
    "            print(\"embedding expansion error:\", e)\n",
    "\n",
    "    # ------------------------------------\n",
    "    # CRPC Federation (remote)\n",
    "    # ------------------------------------\n",
    "    crpc_hits = []\n",
    "    crpc_search_keys = rewrite[\"crpc_keywords\"][:6]\n",
    "    if crime_prov:\n",
    "        crpc_search_keys += crime_prov.get(\"merged\", [])[:6]\n",
    "    for kw in crpc_search_keys:\n",
    "        try:\n",
    "            crpc_hits += crpc_search(kw)\n",
    "        except Exception:\n",
    "            pass\n",
    "    print(f\"CRPC hits: {len(crpc_hits)}\")\n",
    "\n",
    "    # ------------------------------------\n",
    "    # Case federation\n",
    "    # ------------------------------------\n",
    "    cases = case_search(rewrite[\"bns_keywords\"] + (crime_prov.get(\"merged\", []) if crime_prov else []))\n",
    "    print(f\"Case hits: {len(cases)}\")\n",
    "\n",
    "    # ------------------------------------\n",
    "    # Final Integration & Synthesis\n",
    "    # ------------------------------------\n",
    "    print(\"\\n>> STEP 3: FINAL INTEGRATION & SYNTHESIS\")\n",
    "    final = final_answer(query, bns_hits, crpc_hits, cases, crime_provenance=crime_prov)\n",
    "    print(\"\\n=== FINAL ANSWER ===\")\n",
    "    print(final)\n",
    "    print(\"=====================================\\n\")\n",
    "\n",
    "    return {\n",
    "        \"bns\": bns_hits,\n",
    "        \"crpc\": crpc_hits,\n",
    "        \"cases\": cases,\n",
    "        \"crime_provenance\": crime_prov,\n",
    "        \"final\": final\n",
    "    }\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# If invoked directly, run a quick self-test\n",
    "# ------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    if not os.path.exists(BNS_DB_PATH):\n",
    "        print(\"ERROR: cannot find BNS DB at\", BNS_DB_PATH)\n",
    "        raise SystemExit(1)\n",
    "\n",
    "    try:\n",
    "        q = input(\"Enter query: \").strip()\n",
    "    except Exception:\n",
    "        q = \"punishment for rape and murder\"\n",
    "    out = ask(q)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
